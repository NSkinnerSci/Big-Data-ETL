{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8eFW_wl1n39",
        "outputId": "db118f4f-e445-4026-e888-5b124431105e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,013 kB]\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1,998 kB]\n",
            "Ign:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,535 kB]\n",
            "Hit:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,308 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,012 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.3 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,134 kB]\n",
            "Fetched 12.4 MB in 6s (2,151 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "# Activate Spark in our Colab notebook.\n",
        "import os\n",
        "# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.2.2'\n",
        "spark_version = 'spark-3.2.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzCrgs0Z1rnw",
        "outputId": "6aad45c1-ce7e-4dbe-8915-dbe988082a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-03 15:31:21--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  5.78MB/s    in 0.2s    \n",
            "\n",
            "2023-03-03 15:31:22 (5.78 MB/s) - ‘postgresql-42.2.9.jar’ saved [914037/914037]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get postgresql package\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0DuBth0V2PR8"
      },
      "outputs": [],
      "source": [
        "# Import Spark and create a SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"BigData-HW-1\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3W2XJVi2CU-"
      },
      "source": [
        "# Extract the Amazon Data into Spark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na_stw7b1wfU",
        "outputId": "2a673d9e-2385-489f-cfb0-272795f313d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|         US|   18446823|R35T75OLUGHL5C|B000NV6H94|     110804376|Stearns Youth Boa...|        Outdoors|          4|            0|          0|   N|                Y|          Four Stars|          GOOD VALUE| 2015-08-31|\n",
            "|         US|   13724367|R2BV735O46BN33|B000IN0W3Y|     624096774|Primal Wear Men's...|        Outdoors|          5|            0|          0|   N|                Y|          Five Stars|  Excellent quality.| 2015-08-31|\n",
            "|         US|   51001958|R2NBEUGPQQGXP1|B008RBJXFM|     278970944|Osprey Hydraulics...|        Outdoors|          4|            0|          0|   N|                Y|Only Flaw Is The Cap|3rd season using ...| 2015-08-31|\n",
            "|         US|   32866903|R17LLAOJ8ITK0S|B00FK8WUQY|     312877650|CamelBak eddy .75...|        Outdoors|          3|            1|          1|   N|                Y|Poor design leads...|poor construction...| 2015-08-31|\n",
            "|         US|   30907790|R39PEQBT5ISEF4|B00EZA3VW0|     305567912|Children Black Re...|        Outdoors|          1|            0|          0|   N|                Y|Very bad quality,...|Very bad quality,...| 2015-08-31|\n",
            "|         US|   20232229|R3GNM3SU9VHJFT|B006JA8WEG|     842306035|Ibera Bicycle Tri...|        Outdoors|          4|            1|          1|   N|                Y|Nice bag. Should ...|Nice bag. Should ...| 2015-08-31|\n",
            "|         US|   17698862| R2Y81OP0EK467|B002PWFSEO|     451480122|Therm-a-Rest Comp...|        Outdoors|          5|            0|          0|   N|                Y|Very comfortable ...|Gave this to my s...| 2015-08-31|\n",
            "|         US|   38486114|R2LFGSI6HAYH5F|B002DZGKHW|     124386306|Sawyer Products P...|        Outdoors|          5|            1|          1|   N|                Y| Worked like a charm|Went on vacation ...| 2015-08-31|\n",
            "|         US|   26319572|R297G6ED1IQO7W|B00ABA08F6|     991442421|Zippo Hand Warmer...|        Outdoors|          5|            1|          1|   N|                Y|Great item. Gets ...|Great item. Gets ...| 2015-08-31|\n",
            "|         US|   27152337| RE27RFC6101N6|B003Z8WIHC|     886483892|Camp Chef Dutch O...|        Outdoors|          5|            0|          0|   N|                Y|Great value for t...|I am so glad I bo...| 2015-08-31|\n",
            "|         US|   12516845|R3BPDME6E94W8Z|B007CP6UK0|     150224054|3CERA Portable Wi...|        Outdoors|          5|            0|          0|   N|                Y|          Five Stars|        good to have| 2015-08-31|\n",
            "|         US|    3225242|R2P08O1RILUOX3|B003V3U9JK|     343847969|Texsport King Kot...|        Outdoors|          3|            0|          0|   N|                Y|Cot set up inconv...|VERY difficult to...| 2015-08-31|\n",
            "|         US|     961839|R37CVAB03PTDVI|B00Y846HN8|     858088629|Wallygadgets 2 Wh...|        Outdoors|          5|            0|          1|   N|                Y|          Five Stars|Thanks excellent ...| 2015-08-31|\n",
            "|         US|   47796452| RAWNWOGXPCPMD|B00IYQ84VY|     474493517|RainStoppers 34-I...|        Outdoors|          5|            0|          0|   N|                Y|          Five Stars|This umbrella is ...| 2015-08-31|\n",
            "|         US|   32004835| R5DYGP6ASX77M|B002MYCKLY|     920014456|Alpha Deluxe Port...|        Outdoors|          5|            0|          0|   N|                Y|          Five Stars|Love it !! I even...| 2015-08-31|\n",
            "|         US|   23972939|R1O0SAOOGF2KG7|B00EZV69JG|     128489321|Speedfil Z4 BTA B...|        Outdoors|          4|            0|          0|   N|                Y|        Good enough.|This is a fine mo...| 2015-08-31|\n",
            "|         US|   40889047|R35NJUT0U3MU3V|B00AWOT3T8|     571303876|O'Brien Kids Plat...|        Outdoors|          5|            0|          0|   N|                Y| Got Up on First Try|We just bought th...| 2015-08-31|\n",
            "|         US|   11244387|R242C08MF9D1AH|B0000AXTID|     739769424|Kwik-Tek F-5R Pla...|        Outdoors|          5|            0|          0|   N|                Y|They go over an a...|I have these on m...| 2015-08-31|\n",
            "|         US|   20121211| R3RYG8TJTO4E2|B00IFHFJXI|     984009972|Ivation Portable ...|        Outdoors|          5|            0|          0|   N|                Y|Greatest Item I b...|This is the best ...| 2015-08-31|\n",
            "|         US|   25657249|R3IKH1DNY0CP9F|B00KFILTWU|     405521681|GreenInsync Repla...|        Outdoors|          2|            0|          0|   N|                Y|I received this p...|I received this p...| 2015-08-31|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read in the data from an S3 Bucket\n",
        "from pyspark import SparkFiles\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Outdoors_v1_00.tsv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df = spark.read.csv(SparkFiles.get('amazon_reviews_us_Outdoors_v1_00.tsv.gz'), sep=\"\\t\", header=True)\n",
        "\n",
        "df.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cayz-3Q52IM3",
        "outputId": "e0b46ec2-ca6c-49c3-eebe-ed0a17dc4916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 2302401\n"
          ]
        }
      ],
      "source": [
        "# Get the number of rows in the DataFrame.\n",
        "num_rows = df.count()\n",
        "print(f\"Number of rows: {num_rows}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9U0rkGZ2eu7"
      },
      "source": [
        "# Transform the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"review_id_table\"."
      ],
      "metadata": {
        "id": "dUoftWoKtM_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tMYkSIk2d-m",
        "outputId": "7d12dd42-8b7a-4ce1-8ad7-88b6b504eea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review_id , string\n",
            "customer_id , int\n",
            "product_id , string\n",
            "product_parent , int\n",
            "review_date , date\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "|     review_id|customer_id|product_id|product_parent|review_date|\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "|R35T75OLUGHL5C|   18446823|B000NV6H94|     110804376| 2015-08-31|\n",
            "|R2BV735O46BN33|   13724367|B000IN0W3Y|     624096774| 2015-08-31|\n",
            "|R2NBEUGPQQGXP1|   51001958|B008RBJXFM|     278970944| 2015-08-31|\n",
            "|R17LLAOJ8ITK0S|   32866903|B00FK8WUQY|     312877650| 2015-08-31|\n",
            "|R39PEQBT5ISEF4|   30907790|B00EZA3VW0|     305567912| 2015-08-31|\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "# Create the \"review_id_df\" DataFrame with the appropriate columns and data types.\n",
        "\n",
        "# CREATE TABLE review_id_table (\n",
        "#   review_id TEXT PRIMARY KEY NOT NULL,\n",
        "#   customer_id INTEGER,\n",
        "#   product_id TEXT,\n",
        "#   product_parent INTEGER,\n",
        "#   review_date DATE -- this should be in the formate yyyy-mm-dd\n",
        "# );\n",
        "\n",
        "\n",
        "review_id_table = df.selectExpr(\"cast(review_id as string) review_id\",\n",
        "    \"cast(customer_id as int) customer_id\",\n",
        "    \"cast(product_id as string) product_id\",\n",
        "    \"cast(product_parent as int) product_parent\",\n",
        "    \"cast(review_date as date) review_date\")\n",
        "\n",
        "for col in review_id_table.dtypes:\n",
        "    print(col[0]+\" , \"+col[1])\n",
        "\n",
        "review_id_table.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"products\" Table"
      ],
      "metadata": {
        "id": "aAVCFjXhtXO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "g9gTNhT62je4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebebe91-01ac-4848-ce48-596c12e6c8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product_id , string\n",
            "+----------+\n",
            "|product_id|\n",
            "+----------+\n",
            "|B000NV6H94|\n",
            "|B000IN0W3Y|\n",
            "|B008RBJXFM|\n",
            "|B00FK8WUQY|\n",
            "|B00EZA3VW0|\n",
            "+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"products_df\" DataFrame that drops the duplicates in the \"product_id\" and \"product_title columns. \n",
        "\n",
        "# CREATE TABLE products (\n",
        "#   product_id TEXT PRIMARY KEY NOT NULL UNIQUE,\n",
        "#   product_title TEXT\n",
        "# );\n",
        "\n",
        "products_df = df.selectExpr(\"cast(product_id as string) product_id\",\n",
        "    \"cast(product_title as string) product_title\")\n",
        "\n",
        "for col in products_df.dtypes:\n",
        "    print(col[0]+\" , \"+col[1])\n",
        "\n",
        "products_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"customers\" Table"
      ],
      "metadata": {
        "id": "LJHuZ9zut0e5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pF2Vf3c2n2O",
        "outputId": "15ca22d1-e21a-4a18-ab46-ff88145ebc5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "|customer_id|customer_count|\n",
            "+-----------+--------------+\n",
            "|43490052   |5             |\n",
            "|38350414   |1             |\n",
            "|10247520   |2             |\n",
            "|51290010   |1             |\n",
            "|35638967   |1             |\n",
            "|3962209    |1             |\n",
            "|11757653   |2             |\n",
            "|29135708   |1             |\n",
            "|30636778   |115           |\n",
            "|46118365   |1             |\n",
            "|43801871   |6             |\n",
            "|14069091   |1             |\n",
            "|5527036    |1             |\n",
            "|50583551   |3             |\n",
            "|13684282   |1             |\n",
            "|32729496   |1             |\n",
            "|45676353   |6             |\n",
            "|25507311   |2             |\n",
            "|22050232   |1             |\n",
            "|30021189   |2             |\n",
            "+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"customers_df\" DataFrame that groups the data on the \"customer_id\" by the number of times a customer reviewed a product. \n",
        "from pyspark.sql.functions import sum,avg,max,count\n",
        "\n",
        "# CREATE TABLE customers (\n",
        "#   customer_id INT PRIMARY KEY NOT NULL UNIQUE,\n",
        "#   customer_count INT\n",
        "# );\n",
        "\n",
        "\n",
        "customers = df.groupBy(\"customer_id\") \\\n",
        "    .agg(count(\"*\").alias(\"customer_count\")) \\\n",
        "    .show(truncate=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"vine_table\"."
      ],
      "metadata": {
        "id": "8SbTasxbuXGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHQKbmCE2p3Q",
        "outputId": "6c9e393c-34b1-4471-ac94-e242c08ad819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review_id , string\n",
            "star_rating , int\n",
            "helpful_votes , int\n",
            "total_votes , int\n",
            "vine , string\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|     review_id|star_rating|helpful_votes|total_votes|vine|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|R35T75OLUGHL5C|          4|            0|          0|   N|\n",
            "|R2BV735O46BN33|          5|            0|          0|   N|\n",
            "|R2NBEUGPQQGXP1|          4|            0|          0|   N|\n",
            "|R17LLAOJ8ITK0S|          3|            1|          1|   N|\n",
            "|R39PEQBT5ISEF4|          1|            0|          0|   N|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"vine_df\" DataFrame that has the \"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", and \"vine\" columns. \n",
        "# -- vine table\n",
        "# CREATE TABLE vine_table (\n",
        "#   review_id TEXT PRIMARY KEY,\n",
        "#   star_rating INTEGER,\n",
        "#   helpful_votes INTEGER,\n",
        "#   total_votes INTEGER,\n",
        "#   vine TEXT\n",
        "# );\n",
        "\n",
        "vine = df.selectExpr(\"cast(review_id as string) review_id\",\n",
        "    \"cast(star_rating as int) star_rating\",\n",
        "    \"cast(helpful_votes as int) helpful_votes\",\n",
        "    \"cast(total_votes as int) total_votes\",\n",
        "    \"cast(vine as string) vine\")\n",
        "\n",
        "for col in vine.dtypes:\n",
        "    print(col[0]+\" , \"+col[1])\n",
        "\n",
        "vine.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8aTsEjZ2s6L"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "W4dzUKfI2vXM"
      },
      "outputs": [],
      "source": [
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://<endpoint>:5432/my_data_class_db\"\n",
        "config = {\"user\":\"postgres\", \"password\": \"<password>\", \"driver\":\"org.postgresql.Driver\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOxKqMsD2yVs"
      },
      "outputs": [],
      "source": [
        "# Write review_id_df to table in RDS\n",
        "review_id_table.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPXyGVE-2yPJ"
      },
      "outputs": [],
      "source": [
        "# Write products_df to table in RDS\n",
        "products_df.write.jdbc(url=jdbc_url, table='products_df', mode=mode, properties=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHbca4zN2yIa"
      },
      "outputs": [],
      "source": [
        "# Write customers_df to table in RDS\n",
        "customers.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HfOFneW2x_F"
      },
      "outputs": [],
      "source": [
        "# Write vine_df to table in RDS\n",
        "vine.write.jdbc(url=jdbc_url, table='vine', mode=mode, properties=config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}